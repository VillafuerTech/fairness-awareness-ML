{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro-xgb-adult",
            "metadata": {},
            "source": [
                "# XGBoost Training – Adult Dataset\n",
                "\n",
                "This notebook trains an XGBoost classifier on the prepared Adult dataset using:\n",
                "\n",
                "- The modelling-ready dataset: `adult_model_ready.csv`.\n",
                "- A preprocessing pipeline (one-hot encoding for categorical features).\n",
                "- Hyperparameter tuning with `RandomizedSearchCV`.\n",
                "\n",
                "At the end, the best model is evaluated on the held-out test set and persisted to disk."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "imports-markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "imports-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from joblib import dump\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
                "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
                "from sklearn.model_selection import train_test_split  # noqa: F401  # imported as requested\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "RANDOM_STATE = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load-data-markdown",
            "metadata": {},
            "source": [
                "## 2. Load modelling-ready dataset\n",
                "\n",
                "We load `adult_model_ready.csv` generated by the preprocessing notebook. This file:\n",
                "\n",
                "- Has no missing values in key socio-economic fields.\n",
                "- Contains the original `income` target.\n",
                "- Preserves the original split (`train` / `test`) in a `split` column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "load-data-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded dataset with shape: (45194, 16)\n",
                        "Income distribution:\n",
                        " income\n",
                        "<=50K    33988\n",
                        ">50K     11206\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "PROJECT_ROOT = Path('..').resolve()\n",
                "model_path = PROJECT_ROOT / 'data' / 'processed' / 'adult' / 'adult_model_ready.csv'\n",
                "\n",
                "df = pd.read_csv(model_path)\n",
                "print(f'Loaded dataset with shape: {df.shape}')\n",
                "print('Income distribution:\\n', df['income'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "features-target-markdown",
            "metadata": {},
            "source": [
                "## 3. Define features, target, and train/test split\n",
                "\n",
                "- Target: `income` → converted to binary (1 if `>50K`, 0 otherwise).\n",
                "- Features: all columns except `income` and `split`.\n",
                "- Train/Test:\n",
                "  - Training on rows where `split == \"train\"`.\n",
                "  - Testing on rows where `split == \"test\"`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "features-target-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training features shape: (30139, 14)\n",
                        "Test features shape: (15055, 14)\n"
                    ]
                }
            ],
            "source": [
                "split_col = df['split']\n",
                "y = (df['income'] == '>50K').astype(int)\n",
                "\n",
                "train_mask = split_col == 'train'\n",
                "test_mask = split_col == 'test'\n",
                "\n",
                "X_train = df.loc[train_mask].drop(columns=['income', 'split'])\n",
                "y_train = y.loc[train_mask]\n",
                "X_test = df.loc[test_mask].drop(columns=['income', 'split'])\n",
                "y_test = y.loc[test_mask]\n",
                "\n",
                "print(f'Training features shape: {X_train.shape}')\n",
                "print(f'Test features shape: {X_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "preprocess-markdown",
            "metadata": {},
            "source": [
                "## 4. Preprocessing pipeline\n",
                "\n",
                "We build a preprocessing step that:\n",
                "\n",
                "- One-hot encodes all categorical columns.\n",
                "- Passes numeric columns through unchanged.\n",
                "\n",
                "This preprocessing is wrapped together with the XGBoost model in a single `Pipeline`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "preprocess-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Categorical columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
                        "Numeric columns    : ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n"
                    ]
                }
            ],
            "source": [
                "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
                "numeric_cols = X_train.select_dtypes(exclude=['object']).columns.tolist()\n",
                "\n",
                "print('Categorical columns:', categorical_cols)\n",
                "print('Numeric columns    :', numeric_cols)\n",
                "\n",
                "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
                "\n",
                "preprocess = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('categorical', categorical_transformer, categorical_cols),\n",
                "        ('numeric', 'passthrough', numeric_cols),\n",
                "    ]\n",
                ")\n",
                "\n",
                "model = XGBClassifier(\n",
                "    objective='binary:logistic',\n",
                "    eval_metric='logloss',\n",
                "    n_estimators=300,\n",
                "    max_depth=6,\n",
                "    learning_rate=0.1,\n",
                "    subsample=0.9,\n",
                "    colsample_bytree=0.9,\n",
                "    n_jobs=-1,\n",
                "    random_state=RANDOM_STATE,\n",
                ")\n",
                "\n",
                "pipeline = Pipeline(\n",
                "    steps=[\n",
                "        ('preprocess', preprocess),\n",
                "        ('model', model),\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tuning-markdown",
            "metadata": {},
            "source": [
                "## 5. Hyperparameter optimization (RandomizedSearchCV)\n",
                "\n",
                "We use `RandomizedSearchCV` with stratified 5-fold cross-validation to search over:\n",
                "\n",
                "- Number of trees (`n_estimators`).\n",
                "- Depth of trees (`max_depth`).\n",
                "- Learning rate.\n",
                "- Subsample and column subsample ratios.\n",
                "- Regularization (`min_child_weight`, `gamma`, `reg_lambda`).\n",
                "\n",
                "The search is scored with ROC AUC and the best model is refit on the full training data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "tuning-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best parameters: {'model__subsample': 1.0, 'model__reg_lambda': 3, 'model__n_estimators': 600, 'model__min_child_weight': 1, 'model__max_depth': 6, 'model__learning_rate': 0.05, 'model__gamma': 0.3, 'model__colsample_bytree': 1.0}\n",
                        "Best CV ROC AUC: 0.9278956824532658\n"
                    ]
                }
            ],
            "source": [
                "param_distributions = {\n",
                "    'model__n_estimators': [200, 300, 400, 600],\n",
                "    'model__max_depth': [3, 4, 5, 6, 8],\n",
                "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
                "    'model__subsample': [0.6, 0.8, 1.0],\n",
                "    'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
                "    'model__min_child_weight': [1, 5, 10],\n",
                "    'model__gamma': [0, 0.1, 0.3],\n",
                "    'model__reg_lambda': [1, 3, 5, 10],\n",
                "}\n",
                "\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
                "\n",
                "random_search = RandomizedSearchCV(\n",
                "    estimator=pipeline,\n",
                "    param_distributions=param_distributions,\n",
                "    n_iter=40,\n",
                "    scoring='roc_auc',\n",
                "    n_jobs=-1,\n",
                "    cv=cv,\n",
                "    verbose=0,\n",
                "    random_state=RANDOM_STATE,\n",
                "    refit=True,\n",
                ")\n",
                "\n",
                "random_search.fit(X_train, y_train)\n",
                "\n",
                "print('Best parameters:', random_search.best_params_)\n",
                "print('Best CV ROC AUC:', random_search.best_score_)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "evaluation-markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation on held-out test set\n",
                "\n",
                "We evaluate the best model on the original test split using:\n",
                "\n",
                "- Classification report (precision, recall, F1).\n",
                "- ROC AUC.\n",
                "- Confusion matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "evaluation-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Classification report (test set):\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0     0.8957    0.9390    0.9168     11355\n",
                        "           1     0.7801    0.6643    0.7176      3700\n",
                        "\n",
                        "    accuracy                         0.8715     15055\n",
                        "   macro avg     0.8379    0.8016    0.8172     15055\n",
                        "weighted avg     0.8673    0.8715    0.8678     15055\n",
                        "\n",
                        "Test ROC AUC: 0.9282\n",
                        "Confusion matrix:\n",
                        " [[10662   693]\n",
                        " [ 1242  2458]]\n"
                    ]
                }
            ],
            "source": [
                "best_model = random_search.best_estimator_\n",
                "\n",
                "y_pred = best_model.predict(X_test)\n",
                "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "print('\\nClassification report (test set):\\n', classification_report(y_test, y_pred, digits=4))\n",
                "test_roc_auc = roc_auc_score(y_test, y_proba)\n",
                "print(f'Test ROC AUC: {test_roc_auc:.4f}')\n",
                "\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "print('Confusion matrix:\\n', cm)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save-model-markdown",
            "metadata": {},
            "source": [
                "## 7. Save the best model\n",
                "\n",
                "Finally, we persist the tuned pipeline (preprocessing + XGBoost model) using `joblib` so it can be reused later for inference or further analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "save-model-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved model to: /Users/villafuertech/Documents/Academic/University/Septimo_Semestre/Trusthworthy_ML/Projects/3_Project/fairness-project/models/xgb_adult_model.joblib\n"
                    ]
                }
            ],
            "source": [
                "models_dir = PROJECT_ROOT / 'models'\n",
                "models_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "model_file = models_dir / 'xgb_adult_model.joblib'\n",
                "dump(best_model, model_file)\n",
                "print(f'Saved model to: {model_file}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
