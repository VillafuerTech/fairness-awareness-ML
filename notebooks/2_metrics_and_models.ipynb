{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "1f09a903",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from joblib import dump\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
                "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
                "from sklearn.model_selection import train_test_split  # noqa: F401  # imported as requested\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "RANDOM_STATE = 42"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "load_data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded dataset with shape: (45194, 16)\n",
                        "Income distribution:\n",
                        " income\n",
                        "<=50K    33988\n",
                        ">50K     11206\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "PROJECT_ROOT = Path('..').resolve()\n",
                "model_path = PROJECT_ROOT / 'data' / 'processed' / 'adult' / 'adult_model_ready.csv'\n",
                "\n",
                "df = pd.read_csv(model_path)\n",
                "print(f'Loaded dataset with shape: {df.shape}')\n",
                "print('Income distribution:\\n', df['income'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "eda_sex",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "sex\n",
                        "Male      30509\n",
                        "Female    14685\n",
                        "Name: count, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "sex     income\n",
                            "Female  <=50K     0.886347\n",
                            "        >50K      0.113653\n",
                            "Male    <=50K     0.687404\n",
                            "        >50K      0.312596\n",
                            "Name: proportion, dtype: float64"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Quick sanity checks on target vs. sex\n",
                "print(df['sex'].value_counts())\n",
                "df.groupby('sex')['income'].value_counts(normalize=True, dropna=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "eda_race",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "race\n",
                        "White                 38877\n",
                        "Black                  4227\n",
                        "Asian-Pac-Islander     1302\n",
                        "Amer-Indian-Eskimo      435\n",
                        "Other                   353\n",
                        "Name: count, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "race                income\n",
                            "Amer-Indian-Eskimo  <=50K     0.878161\n",
                            "                    >50K      0.121839\n",
                            "Asian-Pac-Islander  <=50K     0.716590\n",
                            "                    >50K      0.283410\n",
                            "Black               <=50K     0.873669\n",
                            "                    >50K      0.126331\n",
                            "Other               <=50K     0.872521\n",
                            "                    >50K      0.127479\n",
                            "White               <=50K     0.737505\n",
                            "                    >50K      0.262495\n",
                            "Name: proportion, dtype: float64"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Quick sanity checks on target vs. race\n",
                "print(df['race'].value_counts())\n",
                "df.groupby('race')['income'].value_counts(normalize=True, dropna=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "fairness_utils",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "def demographic_parity(y, sensitive):\n",
                "    \"\"\"Computes P(Y=1 | group) for each group.\"\"\"\n",
                "    tmp = pd.DataFrame({\"y\": y, \"sensitive\": sensitive})\n",
                "    return tmp.groupby(\"sensitive\")[\"y\"].mean().to_dict()\n",
                "\n",
                "\n",
                "def statistical_parity_difference(y, sensitive, privileged_group):\n",
                "    \"\"\"SPD = P(Y=1 | privileged) - P(Y=1 | unprivileged).\"\"\"\n",
                "    dp = demographic_parity(y, sensitive)\n",
                "    privileged_rate = dp[privileged_group]\n",
                "    # assume binary sensitive attribute here\n",
                "    unprivileged_group = [g for g in dp.keys() if g != privileged_group][0]\n",
                "    unprivileged_rate = dp[unprivileged_group]\n",
                "    return privileged_rate - unprivileged_rate\n",
                "\n",
                "\n",
                "def disparate_impact(y, sensitive, privileged_group):\n",
                "    \"\"\"DI = P(Y=1 | unprivileged) / P(Y=1 | privileged).\"\"\"\n",
                "    dp = demographic_parity(y, sensitive)\n",
                "    privileged_rate = dp[privileged_group]\n",
                "    unprivileged_group = [g for g in dp.keys() if g != privileged_group][0]\n",
                "    unprivaged_rate = dp[unprivileged_group]\n",
                "\n",
                "    # Avoid division-by-zero\n",
                "    if privileged_rate == 0:\n",
                "        return np.nan\n",
                "    return unprivaged_rate / privileged_rate\n",
                "\n",
                "\n",
                "def compute_fairness_metrics(y_true, y_pred, sensitive, privileged_group):\n",
                "    \"\"\"Convenience wrapper returning DP, SPD and DI based on predictions.\"\"\"\n",
                "    results = {}\n",
                "    # DP (based on predictions)\n",
                "    results[\"DP\"] = demographic_parity(y_pred, sensitive)\n",
                "    # SPD (predictions vs sensitive attribute)\n",
                "    results[\"SPD\"] = statistical_parity_difference(y_pred, sensitive, privileged_group)\n",
                "    # DI\n",
                "    results[\"DI\"] = disparate_impact(y_pred, sensitive, privileged_group)\n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "raw_fairness_sex",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Raw fairness (SEX) ===\n",
                        "DP: {'Female': 0.11365338781069118, 'Male': 0.3125962830640139}\n",
                        "SPD: 0.1989428952533227\n",
                        "DI: 0.3635788202491745\n"
                    ]
                }
            ],
            "source": [
                "# Raw fairness metrics on the LABEL vs. sex\n",
                "y_true = (df['income'] == '>50K').astype(int)\n",
                "sensitive_sex = df['sex']\n",
                "\n",
                "dp_sex = demographic_parity(y_true, sensitive_sex)\n",
                "spd_sex = statistical_parity_difference(y_true, sensitive_sex, privileged_group=\"Male\")\n",
                "di_sex = disparate_impact(y_true, sensitive_sex, privileged_group=\"Male\")\n",
                "\n",
                "print(\"=== Raw fairness (SEX) ===\")\n",
                "print(\"DP:\", dp_sex)\n",
                "print(\"SPD:\", spd_sex)\n",
                "print(\"DI:\", di_sex)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "race_binary",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collapse race into White / Non-White\n",
                "df['race_binary'] = df['race'].apply(lambda r: \"White\" if r == \"White\" else \"Non-White\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "raw_fairness_race",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Raw fairness (RACE) ===\n",
                        "DP: {'Non-White': 0.15846129491847397, 'White': 0.26249453404326467}\n",
                        "SPD: 0.1040332391247907\n",
                        "DI: 0.6036746460113191\n"
                    ]
                }
            ],
            "source": [
                "# Raw fairness metrics on the LABEL vs. race (White / Non-White)\n",
                "sensitive_race = df['race_binary']\n",
                "\n",
                "dp_race = demographic_parity(y_true, sensitive_race)\n",
                "spd_race = statistical_parity_difference(y_true, sensitive_race, privileged_group=\"White\")\n",
                "di_race = disparate_impact(y_true, sensitive_race, privileged_group=\"White\")\n",
                "\n",
                "print(\"=== Raw fairness (RACE) ===\")\n",
                "print(\"DP:\", dp_race)\n",
                "print(\"SPD:\", spd_race)\n",
                "print(\"DI:\", di_race)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "train_test_split_and_preprocess",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "# Target\n",
                "y = (df['income'] == '>50K').astype(int)\n",
                "\n",
                "# Features (exclude target and sensitive attributes)\n",
                "X = df.drop(columns=['income', 'sex', 'race', 'race_binary'])\n",
                "\n",
                "# Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.25, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Preprocessing: separate numeric and categorical columns\n",
                "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
                "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
                "\n",
                "preprocess = ColumnTransformer(\n",
                "    transformers=[\n",
                "        (\"num\", StandardScaler(), numeric_cols),\n",
                "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "logistic_regression_model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Logistic Regression baseline\n",
                "lr_clf = Pipeline(steps=[\n",
                "    (\"preprocess\", preprocess),\n",
                "    (\"model\", LogisticRegression(max_iter=500))\n",
                "])\n",
                "\n",
                "lr_clf.fit(X_train, y_train)\n",
                "y_pred_lr = lr_clf.predict(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "random_forest_model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Random Forest model\n",
                "rf_clf = Pipeline(steps=[\n",
                "    (\"preprocess\", preprocess),\n",
                "    (\"model\", RandomForestClassifier(\n",
                "        n_estimators=300,\n",
                "        max_depth=None,\n",
                "        random_state=42,\n",
                "        n_jobs=-1\n",
                "    ))\n",
                "])\n",
                "\n",
                "rf_clf.fit(X_train, y_train)\n",
                "y_pred_rf = rf_clf.predict(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "xgboost_model",
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost model\n",
                "xgb_clf = Pipeline(steps=[\n",
                "    (\"preprocess\", preprocess),\n",
                "    (\"model\", XGBClassifier(\n",
                "        n_estimators=300,\n",
                "        max_depth=5,\n",
                "        learning_rate=0.1,\n",
                "        subsample=0.8,\n",
                "        colsample_bytree=0.8,\n",
                "        random_state=42,\n",
                "        n_jobs=-1,\n",
                "        objective='binary:logistic',\n",
                "        eval_metric='logloss'\n",
                "    ))\n",
                "])\n",
                "\n",
                "xgb_clf.fit(X_train, y_train)\n",
                "y_pred_xgb = xgb_clf.predict(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "extract_sensitive_test",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract sensitive attributes for the TEST split\n",
                "sex_test = df.loc[X_test.index, 'sex']\n",
                "race_test = df.loc[X_test.index, 'race_binary']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "metrics_and_fairness",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "===== Logistic Regression PERFORMANCE =====\n",
                        "Accuracy : 0.8474201256748385\n",
                        "Precision: 0.7404103479036575\n",
                        "Recall   : 0.5924339757316203\n",
                        "F1-score : 0.6582077716098335\n",
                        "\n",
                        "===== Logistic Regression FAIRNESS: SEX =====\n",
                        "{'DP': {'Female': 0.08263114976895895, 'Male': 0.2543307086614173}, 'SPD': 0.17169955889245836, 'DI': 0.32489647122779525}\n",
                        "\n",
                        "===== Logistic Regression FAIRNESS: RACE =====\n",
                        "{'DP': {'Non-White': 0.12538040170419965, 'White': 0.2108533554266777}, 'SPD': 0.08547295372247807, 'DI': 0.5946331821491905}\n",
                        "\n",
                        "===== Random Forest PERFORMANCE =====\n",
                        "Accuracy : 0.8502522347110364\n",
                        "Precision: 0.7355687606112055\n",
                        "Recall   : 0.6184867951463241\n",
                        "F1-score : 0.6719658782473827\n",
                        "\n",
                        "===== Random Forest FAIRNESS: SEX =====\n",
                        "{'DP': {'Female': 0.08833922261484099, 'Male': 0.26653543307086613}, 'SPD': 0.17819621045602513, 'DI': 0.3314351926760652}\n",
                        "\n",
                        "===== Random Forest FAIRNESS: RACE =====\n",
                        "{'DP': {'Non-White': 0.1363359707851491, 'White': 0.2207953603976802}, 'SPD': 0.08445938961253108, 'DI': 0.6174766106479361}\n",
                        "\n",
                        "===== XGBoost PERFORMANCE =====\n",
                        "Accuracy : 0.8671563855208425\n",
                        "Precision: 0.7785867237687366\n",
                        "Recall   : 0.6488222698072805\n",
                        "F1-score : 0.7078061125170333\n",
                        "\n",
                        "===== XGBoost FAIRNESS: SEX =====\n",
                        "{'DP': {'Female': 0.09132916553411254, 'Male': 0.26233595800524934}, 'SPD': 0.17100679247113681, 'DI': 0.3481381897798587}\n",
                        "\n",
                        "===== XGBoost FAIRNESS: RACE =====\n",
                        "{'DP': {'Non-White': 0.12903225806451613, 'White': 0.2198632974316487}, 'SPD': 0.09083103936713258, 'DI': 0.586874933523772}\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "def print_model_results(model_name, y_true, y_pred, sex_test, race_test):\n",
                "    print(f\"\\n===== {model_name} PERFORMANCE =====\")\n",
                "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
                "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
                "    print(\"Recall   :\", recall_score(y_true, y_pred))\n",
                "    print(\"F1-score :\", f1_score(y_true, y_pred))\n",
                "\n",
                "    print(f\"\\n===== {model_name} FAIRNESS: SEX =====\")\n",
                "    print(compute_fairness_metrics(\n",
                "        y_true=y_true,\n",
                "        y_pred=y_pred,\n",
                "        sensitive=sex_test,\n",
                "        privileged_group=\"Male\"\n",
                "    ))\n",
                "\n",
                "    print(f\"\\n===== {model_name} FAIRNESS: RACE =====\")\n",
                "    print(compute_fairness_metrics(\n",
                "        y_true=y_true,\n",
                "        y_pred=y_pred,\n",
                "        sensitive=race_test,\n",
                "        privileged_group=\"White\"\n",
                "    ))\n",
                "\n",
                "# Evaluate all three models\n",
                "print_model_results(\"Logistic Regression\", y_test, y_pred_lr, sex_test, race_test)\n",
                "print_model_results(\"Random Forest\", y_test, y_pred_rf, sex_test, race_test)\n",
                "print_model_results(\"XGBoost\", y_test, y_pred_xgb, sex_test, race_test)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
